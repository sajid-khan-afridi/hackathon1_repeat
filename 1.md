# Physical AI & Humanoid Robotics Textbook - Project Constitution

## PROJECT IDENTITY

**Project Name:** Physical AI & Humanoid Robotics Textbook
**Project Type:** Educational Platform with Integrated AI Features
**Target Audience:** Graduate-level students learning Physical AI, ROS 2, NVIDIA Isaac, and Humanoid Robotics
**Primary Goal:** Deliver an accessible, interactive, multilingual robotics textbook with AI-powered learning assistance

---

## AGENT ARCHITECTURE

### 1. Orchestrator Agent
**Purpose:** Project coordination, task delegation, spec compliance
**Skills:** None (pure orchestration logic)
**Responsibilities:**
- Coordinate work across all agents
- Ensure spec compliance and constitution adherence
- Resolve inter-agent conflicts
- Monitor project progress and quality gates

**Success Criteria:**
- All phases complete on schedule with quality gates passed
- No agent conflicts escalate beyond resolution
- PHRs created for all significant work
- ADRs suggested for architectural decisions

**Does NOT Own:**
- Direct code implementation
- Content authoring
- Infrastructure provisioning

---

### 2. ContentWriter Agent
**Purpose:** Technical chapter authoring and educational content creation
**Skills:** `mdx-writer`
**Responsibilities:**
- Author technical chapters in MDX format
- Create code examples and exercises
- Ensure learning objectives are met
- Maintain consistent technical depth

**Success Criteria:**
- Chapters match learning objectives (100%)
- Code examples execute without errors (100%)
- Technical accuracy validated by domain experts
- Readability score appropriate for graduate level (Flesch-Kincaid 12-14)

**Does NOT Own:**
- Frontend UI implementation
- Backend service development
- Translation or personalization logic

---

### 3. DocusaurusBuilder Agent
**Purpose:** Frontend development and site infrastructure
**Skills:** `docusaurus-init`, `react-components`, `github-pages-deploy`
**Responsibilities:**
- Initialize and configure Docusaurus v3 site
- Develop React components for interactive features
- Implement responsive design and dark mode
- Deploy to GitHub Pages

**Success Criteria:**
- Lighthouse scores: Performance > 90, Accessibility > 90, Best Practices > 90
- Mobile responsive (320px to 2560px viewport)
- Dark mode toggle works across all pages
- Build time < 5 minutes for full site

**Does NOT Own:**
- Content authoring (MDX files)
- Backend API development
- Authentication logic

---

### 4. RAGArchitect Agent
**Purpose:** Backend/AI engineering for RAG chatbot system
**Skills:** `qdrant-vectorstore`, `neon-postgres`, `fastapi-backend`, `openai-agents-sdk`
**Responsibilities:**
- Design and implement vector search pipeline
- Build FastAPI backend for RAG queries
- Integrate OpenAI Agents SDK for intelligent responses
- Optimize retrieval accuracy and latency

**Success Criteria:**
- Retrieval relevance score (NDCG@10) > 0.8
- Query response time p95 < 3 seconds (end-to-end)
- No hallucinations on test question set (100% faithfulness)
- Vector store handles 1000+ chapter chunks efficiently

**Performance Budget:**
- Embedding generation: < 500ms
- Vector search: < 1s
- LLM generation: < 1.5s
- Total: < 3s (p95)

**Does NOT Own:**
- Frontend chatbot UI
- User authentication
- Content translation

---

### 5. AuthEngineer Agent
**Purpose:** Authentication and user management
**Skills:** `better-auth-setup`, `user-profiling`, `neon-postgres`
**Responsibilities:**
- Implement Better Auth for authentication flows
- Design user profile schema in Neon Postgres
- Handle session management and token refresh
- Implement user preference storage

**Success Criteria:**
- Email + Google OAuth functional (100% success rate)
- Session tokens expire after 24h and refresh properly
- User profiles store learning preferences correctly
- Auth flow passes all security tests (OWASP Top 10)

**Security Requirements:**
- No plaintext passwords stored
- JWT tokens signed with RS256
- CSRF protection enabled
- Rate limiting: 10 failed login attempts â†’ 15min lockout

**Does NOT Own:**
- Content personalization algorithms
- RAG chatbot logic
- Frontend component development

---

### 6. PersonalizationEngine Agent
**Purpose:** Adaptive content delivery based on user profiles
**Skills:** `content-adapter`, `user-profiling`
**Responsibilities:**
- Analyze user learning preferences
- Adapt content difficulty and depth
- Recommend chapters based on skill level
- Track learning progress

**Success Criteria:**
- Personalization response time < 2 seconds
- Adaptation accuracy validated by user feedback (> 70% satisfaction)
- Skill level classification accuracy > 80%
- Recommendation relevance score > 0.75

**Does NOT Own:**
- Content authoring
- Authentication logic
- Translation services

---

### 7. TranslationService Agent
**Purpose:** Urdu translation with technical term preservation
**Skills:** `urdu-translator`, `react-components`
**Responsibilities:**
- Translate technical content to Urdu
- Preserve technical terms (ROS, Python, etc.)
- Implement RTL UI components
- Validate translation quality

**Success Criteria:**
- Translation generation: < 5s per chapter
- Technical term preservation: 100% (validated against term list)
- Grammar correctness: Pass native speaker review
- RTL rendering: No layout breaks on any page

**Does NOT Own:**
- Original content creation
- Authentication logic
- Backend API development

---

## CODE QUALITY PRINCIPLES

### TypeScript Standards
1. **Strict Mode Enabled:** No `any` types except in explicit migration scenarios
2. **Type Coverage:** 100% for all public APIs
3. **JSDoc Required:** All exported functions, components, and types
4. **Naming Conventions:**
   - Components: PascalCase
   - Functions: camelCase
   - Constants: UPPER_SNAKE_CASE
   - Files: kebab-case

### Python Standards
1. **PEP 8 Compliance:** Enforced via `black` and `flake8`
2. **Type Hints:** Required for all function signatures (mypy strict mode)
3. **Docstrings:** Google-style for all public functions and classes
4. **Async First:** Use `async/await` for all I/O operations

### Documentation Requirements
1. **README:** Each major directory has README.md explaining structure
2. **API Docs:** OpenAPI/Swagger for all FastAPI endpoints
3. **Component Docs:** Storybook or equivalent for React components
4. **Architecture Docs:** ADRs for all significant decisions

### Security Standards
1. **No Secrets in Code:** Use `.env` files, never commit
2. **Input Validation:** Sanitize all user input before storage/processing
3. **Dependency Scanning:** Run `npm audit` and `pip-audit` weekly
4. **HTTPS Only:** All external API calls use HTTPS

---

## TESTING STANDARDS

### Unit Testing
**Minimum Coverage:** 80% for all core functionality
**Framework:** Jest (TypeScript), Pytest (Python)
**Requirements:**
- All utility functions tested
- All business logic tested
- Edge cases and error paths covered

### Component Testing
**Framework:** React Testing Library
**Requirements:**
- All interactive components tested
- User interactions simulated (click, input, navigation)
- Accessibility checks included (axe-core)
- Snapshot tests for visual regression

### Integration Testing
**RAG Pipeline:**
- Test end-to-end query flow (input â†’ embedding â†’ search â†’ generation)
- Validate relevance scores on 50-question test set
- Measure latency for representative queries
- **Pass Criteria:** NDCG@10 > 0.8, p95 latency < 3s

**Authentication Flow:**
- Test email signup, login, logout
- Test Google OAuth flow
- Test token refresh and expiration
- **Pass Criteria:** 100% success on test scenarios

### Translation Testing
**Validation:**
- 100% technical term preservation (automated check against term list)
- Grammar correctness (native speaker review sample)
- RTL rendering (visual regression tests)
- **Pass Criteria:** Zero layout breaks, term preservation 100%

### End-to-End Testing
**Framework:** Playwright
**Critical User Journeys:**
1. New user signup â†’ browse chapters â†’ ask RAG question â†’ get answer
2. Existing user login â†’ personalized recommendations â†’ bookmark chapter
3. User switches to Urdu â†’ RTL layout renders â†’ translation displays correctly

**Pass Criteria:** All journeys complete without errors

---

## USER EXPERIENCE CONSISTENCY

### Responsive Design
**Breakpoints:**
- Mobile: 320px - 767px
- Tablet: 768px - 1023px
- Desktop: 1024px+

**Requirements:**
- Touch targets â‰¥ 44x44px (mobile)
- Readable text without zoom (16px base font size)
- No horizontal scrolling at any breakpoint

### Dark Mode
**Implementation:**
- System preference detection on first visit
- Manual toggle persists in localStorage
- All components support dark mode
- Color contrast ratios meet WCAG AA (4.5:1 text, 3:1 UI)

### Accessibility (WCAG 2.1 AA)
**Requirements:**
- All images have alt text
- Keyboard navigation works for all interactive elements
- Focus indicators visible and styled
- Screen reader tested (NVDA/JAWS)
- No color-only information conveyance

### Loading States
**Guidelines:**
- Skeleton screens for content loading
- Spinners for async operations < 3s
- Progress bars for operations > 3s
- Error boundaries catch and display friendly errors

### Error Handling
**User-Facing Errors:**
- Clear, actionable error messages
- i18n-compatible (English + Urdu)
- Retry options where applicable
- Contact support link for critical errors

**Backend Errors:**
- Logged with correlation IDs
- Structured logging (JSON format)
- Severity levels (INFO, WARN, ERROR, CRITICAL)

### RTL Support (Urdu)
**Requirements:**
- Text direction switches to RTL
- Layout mirrors (sidebar, navigation)
- Icons and buttons flip appropriately
- No hardcoded LTR assumptions in CSS

---

## PERFORMANCE REQUIREMENTS

### Frontend Performance
**Metrics:**
- Initial page load (First Contentful Paint): < 1.5s
- Time to Interactive: < 3s
- Largest Contentful Paint: < 2.5s
- Cumulative Layout Shift: < 0.1

**Optimization:**
- Code splitting by route
- Image lazy loading
- Font subsetting
- CDN for static assets

### Backend Performance
**API Latency (p95):**
- GET endpoints: < 200ms
- POST endpoints: < 500ms
- RAG query: < 3s (end-to-end)
- Translation: < 5s per chapter

**Optimization:**
- Database query indexing
- Redis caching for frequent queries
- Connection pooling
- Async operations for I/O

### RAG Chatbot Performance
**Detailed Budget:**
- Embed user query (OpenAI API): < 500ms
- Search Qdrant (top 10 chunks): < 1s
- Generate answer (OpenAI Agents SDK): < 1.5s
- **Total:** < 3s (p95)

**Optimization:**
- Batch embedding requests where possible
- Qdrant HNSW index optimization (M=16, ef_construct=100)
- Prompt caching for repeated queries
- Rate limiting to protect quotas

### Translation Performance
**Target:** < 5s per chapter
**Optimization:**
- Stream translation (yield chunks as available)
- Cache translated chapters
- Background job for bulk translation

### Lighthouse Targets
- Performance: > 90
- Accessibility: > 90
- Best Practices: > 90
- SEO: > 90

---

## ARCHITECTURE DECISIONS

### Frontend Architecture
**Framework:** Docusaurus v3 (React-based static site generator)
**Rationale:** Built for documentation, excellent DX, plugin ecosystem
**Language:** TypeScript (strict mode)
**Styling:** CSS Modules + Docusaurus theme tokens
**State Management:** React Context for global state (user, theme)

### Backend Architecture
**Framework:** FastAPI (Python 3.11+)
**Rationale:** High performance, async support, auto OpenAPI docs
**API Design:** RESTful + OpenAPI 3.1
**Deployment:** Containerized (Docker)

### Database Architecture
**Relational Data:** Neon Serverless Postgres (Free Tier)
**Schema:**
- `users` table (auth, profile)
- `chat_history` table (user queries, bot responses)
- `user_preferences` table (learning level, bookmarks)

**Vector Data:** Qdrant Cloud (Free Tier, 1GB)
**Collections:**
- `textbook_chunks` (chapter embeddings, metadata)

### AI/ML Architecture
**Embedding Model:** OpenAI `text-embedding-3-small` (1536 dimensions)
**LLM:** OpenAI GPT-4o-mini via Agents SDK
**Rationale:** Cost-effective, good performance for educational content

### Authentication Architecture
**Library:** Better Auth (email + Google OAuth)
**Session Storage:** Neon Postgres
**Token Type:** JWT (RS256 signing)
**Expiry:** 24h access token, 30d refresh token

### Deployment Architecture
**Frontend:** GitHub Pages (free static hosting)
**Backend:** Railway / Render free tier (containerized FastAPI)
**CI/CD:** GitHub Actions (build, test, deploy)

### Free Tier Constraints
**Respected Limits:**
- Qdrant: 1GB storage (~100k chunks)
- Neon: 0.5GB storage, 100 compute hours/month
- OpenAI: Rate limits per API key tier
- GitHub Pages: 100GB bandwidth/month

---

## DEVELOPMENT PHASES

### Phase 1: Book Infrastructure (Owner: DocusaurusBuilder)
**Duration Target:** Foundation work
**Deliverables:**
- Docusaurus v3 initialized with TypeScript
- Custom theme with dark mode
- Responsive layout (mobile, tablet, desktop)
- GitHub Pages deployment configured

**Quality Gate:**
- Site builds without errors
- Deploys to GitHub Pages successfully
- Lighthouse scores all > 85
- Dark mode toggle functional

---

### Phase 2: Content Creation (Owner: ContentWriter)
**Duration Target:** Content development
**Deliverables:**
- 10 sample chapters (MDX format)
- Code examples tested and runnable
- Learning objectives per chapter
- Exercises with solutions

**Quality Gate:**
- All chapters render correctly in Docusaurus
- Code examples execute without errors (tested in CI)
- Peer review completed by domain expert
- Readability appropriate for target audience

---

### Phase 3: RAG Chatbot Core (Owner: RAGArchitect)
**Duration Target:** AI feature implementation
**Deliverables:**
- Vector database populated with chapter chunks
- FastAPI backend with `/query` endpoint
- OpenAI Agents SDK integration
- Basic chatbot UI (simplified)

**Quality Gate:**
- Retrieval NDCG@10 > 0.8 on test set
- Response time p95 < 3s
- No hallucinations on 50-question test set
- API documented with OpenAPI

---

### Phase 4A: Authentication (Owner: AuthEngineer)
**Duration Target:** Security implementation
**Deliverables:**
- Better Auth configured (email + Google)
- User profile schema in Neon Postgres
- Session management functional
- Protected routes implemented

**Quality Gate:**
- Email signup, login, logout work (100% success)
- Google OAuth flow functional
- Tokens expire and refresh correctly
- Passes OWASP Top 10 security checklist

---

### Phase 4B: Personalization (Owner: PersonalizationEngine)
**Duration Target:** Adaptive feature
**Deliverables:**
- User skill level classification
- Personalized chapter recommendations
- Learning progress tracking
- Adaptive content depth

**Quality Gate:**
- Personalization response time < 2s
- Recommendation relevance > 0.75
- User feedback survey shows > 70% satisfaction

---

### Phase 5: Translation (Owner: TranslationService)
**Duration Target:** Multilingual support
**Deliverables:**
- Urdu translation for all chapters
- RTL layout components
- Language toggle UI
- Technical term glossary

**Quality Gate:**
- Translation time < 5s per chapter
- 100% technical term preservation (automated check)
- RTL layout renders without breaks (visual regression)
- Native speaker review passes for sample chapters

---

### Phase 6: Integration & Deployment (Owner: Orchestrator)
**Duration Target:** Final integration
**Deliverables:**
- All features integrated into production
- End-to-end testing complete
- Documentation finalized
- Deployment pipeline automated

**Quality Gate:**
- All critical user journeys pass E2E tests
- Performance requirements met (Lighthouse > 90)
- Security audit passed
- Production deployment successful

---

## ERROR HANDLING POLICY

### API Error Handling
**Requirements:**
- All external API calls have timeout (default 30s)
- Retry logic with exponential backoff (3 attempts)
- Circuit breaker for repeated failures
- Correlation IDs for request tracing

**Error Response Format:**
```json
{
  "error": {
    "code": "EMBEDDING_TIMEOUT",
    "message": "Failed to generate embedding",
    "correlation_id": "abc-123-def",
    "timestamp": "2025-12-10T12:34:56Z"
  }
}
```

### User-Facing Errors
**Guidelines:**
- Clear, non-technical language
- Actionable next steps
- Avoid exposing internal details
- i18n-compatible (English + Urdu)

**Examples:**
- âœ… "Unable to find relevant answers. Try rephrasing your question."
- âŒ "Vector search returned empty results from Qdrant."

### Graceful Degradation
**Strategies:**
- RAG failure â†’ Show static FAQ content
- Translation unavailable â†’ English fallback
- Personalization error â†’ Default recommendations
- Auth service down â†’ Allow guest browsing (no chat)

---

## SECURITY PRINCIPLES

### Secret Management
**Rules:**
- No API keys, passwords, or tokens in code
- Use `.env` files for local development
- Use GitHub Secrets for CI/CD
- Rotate secrets quarterly (document in ADR)

**Environment Variables:**
```
OPENAI_API_KEY=sk-...
QDRANT_API_KEY=...
NEON_DATABASE_URL=postgres://...
GITHUB_CLIENT_SECRET=...
```

### Input Sanitization
**Requirements:**
- Sanitize all user input before storage
- Prevent SQL injection (use parameterized queries)
- Prevent XSS (escape HTML in user content)
- Validate file uploads (type, size)

### Authentication Security
**Requirements:**
- Passwords hashed with bcrypt (cost factor 12)
- JWT signed with RS256 (not HS256)
- CSRF tokens for state-changing requests
- Rate limiting on auth endpoints

**Rate Limits:**
- Login attempts: 10 per 15 minutes per IP
- Signup: 5 per hour per IP
- Password reset: 3 per hour per email

### Data Privacy
**Principles:**
- Collect minimum necessary user data
- Store chat history for max 30 days (user-deletable)
- No PII in vector database
- GDPR-compliant data export/deletion

---

## DATA GOVERNANCE

### Vector Store (Qdrant)
**Contents:** Textbook chapter chunks + metadata
**Schema:**
```json
{
  "id": "chapter-3-section-2-chunk-5",
  "vector": [0.123, ...],
  "payload": {
    "chapter": "3",
    "section": "2",
    "title": "ROS 2 Publishers",
    "content": "...",
    "tags": ["ros2", "publisher"]
  }
}
```
**Retention:** Indefinite (reference material)
**PII:** None allowed

### Relational Database (Neon Postgres)
**Tables:**
1. `users` - Auth info, encrypted email
2. `user_profiles` - Learning preferences, skill level
3. `chat_history` - User queries + bot responses (30-day retention)
4. `user_bookmarks` - Saved chapters

**Encryption:** At rest (Neon default), in transit (TLS 1.3)
**Backup:** Neon automatic daily backups (7-day retention)

### Embeddings Versioning
**Strategy:**
- Store embedding model name + version in metadata
- On model upgrade, re-embed all content
- Keep old embeddings for rollback (7 days)

---

## QUALITY GATES

### Phase 1 Exit Criteria (Book Infrastructure)
- [ ] Docusaurus builds successfully (`npm run build`)
- [ ] Site deploys to GitHub Pages without errors
- [ ] Lighthouse Performance > 85
- [ ] Lighthouse Accessibility > 90
- [ ] Dark mode toggle functional
- [ ] Responsive on mobile (320px), tablet (768px), desktop (1024px)
- [ ] PHR created documenting infrastructure decisions

### Phase 2 Exit Criteria (Content Creation)
- [ ] 10 chapters authored in MDX format
- [ ] All code examples execute without errors (CI test)
- [ ] Learning objectives defined per chapter
- [ ] Peer review completed by domain expert
- [ ] Readability Flesch-Kincaid score 12-14
- [ ] PHR created summarizing content milestones

### Phase 3 Exit Criteria (RAG Chatbot Core)
- [ ] Vector database has 1000+ chunks
- [ ] `/query` API endpoint functional and documented
- [ ] NDCG@10 > 0.8 on 50-question test set
- [ ] Response time p95 < 3s (measured in CI)
- [ ] Zero hallucinations on test set
- [ ] ADR created for RAG architecture decisions
- [ ] PHR created documenting RAG implementation

### Phase 4A Exit Criteria (Authentication)
- [ ] Email signup, login, logout work (100% success on test scenarios)
- [ ] Google OAuth functional
- [ ] JWT tokens expire after 24h and refresh correctly
- [ ] OWASP Top 10 checklist passed (security audit)
- [ ] Rate limiting functional (tested with load tool)
- [ ] PHR created documenting auth implementation

### Phase 4B Exit Criteria (Personalization)
- [ ] User skill level classification functional
- [ ] Personalized recommendations display correctly
- [ ] Response time < 2s (measured)
- [ ] Recommendation relevance > 0.75 (A/B test)
- [ ] PHR created documenting personalization logic

### Phase 5 Exit Criteria (Translation)
- [ ] All 10 chapters translated to Urdu
- [ ] Translation time < 5s per chapter (measured)
- [ ] 100% technical term preservation (automated check)
- [ ] RTL layout renders correctly (visual regression tests)
- [ ] Native speaker review passes for 3 sample chapters
- [ ] PHR created documenting translation approach

### Phase 6 Exit Criteria (Integration & Deployment)
- [ ] All critical user journeys pass E2E tests (Playwright)
- [ ] Lighthouse scores: Performance > 90, Accessibility > 90
- [ ] Production deployment successful
- [ ] Monitoring and alerting configured
- [ ] Documentation complete (README, API docs, ADRs)
- [ ] PHR created documenting final integration

---

## GOVERNANCE

### Decision Authority
**Orchestrator Agent:**
- Final authority on task prioritization
- Resolves inter-agent conflicts
- Approves phase transitions (quality gate checks)

**Architecture Changes:**
- Require ADR creation (via `/sp.adr`)
- User approval required for major changes
- Document in `history/adr/`

**Spec Changes:**
- Must pass constitution compliance check
- Require Orchestrator approval
- Update PHR with rationale

### Escalation Paths
**Agent Conflicts:**
1. Agents attempt resolution via shared context
2. If unresolved, escalate to Orchestrator
3. Orchestrator decides and documents in PHR

**Ambiguity in Requirements:**
1. Agent identifies ambiguity
2. Uses "Human as Tool" strategy (ask user 2-3 targeted questions)
3. User provides clarification
4. Update spec and document in PHR

**Budget/Scope Exceeded:**
1. Agent halts work
2. Reports to Orchestrator with details
3. Orchestrator escalates to user for decision
4. Document decision in ADR if architectural

**Technical Blocker:**
1. Agent investigates and documents issue
2. Proposes 2-3 solutions with tradeoffs
3. Escalates to user for decision
4. Document in ADR if significant

### Skill Invocation Rules
**Requirement:** Skills MUST be invoked through designated agents
**Enforcement:**
- `mdx-writer` â†’ Only via ContentWriter agent
- `qdrant-vectorstore` â†’ Only via RAGArchitect agent
- `better-auth-setup` â†’ Only via AuthEngineer agent

**Rationale:** Ensures domain expertise and prevents skill misuse

### Priority Framework
**Order of Priorities:**
1. **Core Functionality** - Book rendering, RAG chatbot, authentication
2. **Quality & Security** - Testing, OWASP compliance, performance
3. **User Experience** - Responsive design, accessibility, dark mode
4. **Bonus Features** - Personalization, translation, advanced analytics

**Principle:** Deliver working core before adding enhancements

---

## NON-FUNCTIONAL REQUIREMENTS (NFRs)

### Reliability
**Uptime Target:** 99% (monthly basis)
**Error Budget:** 1% downtime = ~7 hours/month
**Degradation Strategy:**
- RAG failure â†’ Static FAQ fallback
- Auth service down â†’ Guest mode
- Translation unavailable â†’ English fallback

### Observability
**Logging:**
- Structured JSON logs
- Correlation IDs for request tracing
- Log levels: DEBUG, INFO, WARN, ERROR, CRITICAL
- Retention: 30 days

**Metrics:**
- API latency (p50, p95, p99)
- Error rates (per endpoint)
- RAG relevance scores (daily aggregate)
- User engagement (sessions, queries)

**Tracing:**
- OpenTelemetry for distributed tracing
- Trace RAG pipeline: embed â†’ search â†’ generate

### Alerting
**Critical Alerts:**
- API error rate > 5% (5-minute window) â†’ Notify immediately
- RAG response time p95 > 5s â†’ Notify immediately
- Database connection pool exhausted â†’ Notify immediately

**Warning Alerts:**
- Lighthouse score drops below 85 â†’ Notify daily digest
- Translation cache hit rate < 70% â†’ Notify weekly

### Cost Management
**Free Tier Monitoring:**
- Qdrant: Alert at 80% of 1GB storage
- Neon: Alert at 80 compute hours (100h/month limit)
- OpenAI: Track API spend, alert at $50/month

**Unit Economics:**
- Embedding cost: ~$0.0001 per query (OpenAI text-embedding-3-small)
- LLM generation: ~$0.002 per query (GPT-4o-mini)
- Target: < $0.01 per user per month (at 10 queries/user/month)

---

## OPERATIONAL READINESS

### Runbooks
**Common Tasks:**
1. **Deploy New Version**
   - Run CI/CD pipeline (`git push` to main)
   - Verify deployment health checks
   - Monitor error rates for 15 minutes

2. **Roll Back Deployment**
   - Revert to previous GitHub Pages deployment
   - Redeploy backend container (previous tag)
   - Verify rollback success

3. **Re-Embed Content (Model Upgrade)**
   - Export all chapters from Docusaurus
   - Run batch embedding script
   - Upload to Qdrant with new model version metadata
   - Run relevance tests to validate

4. **Handle OpenAI Rate Limit**
   - Enable rate limiting at application layer
   - Queue requests with backoff
   - Display user-friendly message: "High demand, please retry in 1 minute"

### Deployment Strategy
**CI/CD Pipeline:**
1. Push to main branch â†’ Trigger GitHub Actions
2. Run linters (ESLint, Prettier, Black, Flake8)
3. Run unit tests (Jest, Pytest)
4. Run integration tests (API, RAG)
5. Build Docusaurus site
6. Deploy to GitHub Pages (frontend)
7. Build and push Docker image (backend)
8. Deploy to Railway/Render

**Rollback Procedure:**
- Frontend: Revert GitHub Pages deployment (via Actions)
- Backend: Redeploy previous Docker image tag

### Feature Flags
**Use Cases:**
- Gradual rollout of personalization (A/B test)
- Emergency disable of translation service
- Beta features for select users

**Implementation:** Environment variables or simple config file

### Backward Compatibility
**API Versioning:**
- Version in URL path: `/api/v1/query`
- Maintain v1 for 6 months after v2 release
- Document deprecation in OpenAPI spec

---

## RISK ANALYSIS AND MITIGATION

### Top 3 Risks

#### Risk 1: OpenAI API Cost Overrun
**Impact:** High (budget exhaustion)
**Likelihood:** Medium
**Blast Radius:** All RAG functionality
**Mitigation:**
- Implement rate limiting per user (10 queries/hour free, 50 queries/hour authenticated)
- Cache frequent queries (Redis, 1-hour TTL)
- Monitor spend daily, alert at $50/month threshold
- Fallback: Disable chatbot, show static FAQ

**Kill Switch:** Environment variable `ENABLE_RAG=false`

---

#### Risk 2: Qdrant Free Tier Storage Limit (1GB)
**Impact:** High (RAG failure if exceeded)
**Likelihood:** Medium (depends on content growth)
**Blast Radius:** Vector search fails
**Mitigation:**
- Monitor storage usage (alert at 80%)
- Compress embeddings (dimensionality reduction if needed)
- Prune old/unused chunks
- Upgrade to paid tier if necessary (last resort)

**Kill Switch:** Fallback to keyword search (basic)

---

#### Risk 3: Translation Quality Issues
**Impact:** Medium (poor UX for Urdu users)
**Likelihood:** Medium
**Blast Radius:** Urdu translation feature
**Mitigation:**
- Manual review by native speaker (sample chapters)
- Technical term glossary (100% preservation enforced)
- User feedback mechanism (report translation errors)
- Iterative improvement based on feedback

**Kill Switch:** Disable Urdu toggle, show English only

---

## EVALUATION AND VALIDATION

### Definition of Done (Per Phase)
**Criteria:**
1. All acceptance criteria met (from spec)
2. Tests pass (unit, integration, E2E as applicable)
3. Code review completed (peer or agent review)
4. Documentation updated (README, API docs, ADRs)
5. PHR created documenting work
6. Quality gate checklist passed

### Output Validation
**Format Validation:**
- PHRs follow template structure (no missing fields)
- ADRs use standard format (Context, Decision, Consequences)
- Code passes linters (ESLint, Prettier, Black, Flake8)

**Requirements Validation:**
- Unit tests validate business logic
- Integration tests validate system interactions
- E2E tests validate user journeys

**Safety Validation:**
- OWASP Top 10 checklist passed
- Dependency scanning (no critical vulnerabilities)
- Input sanitization verified

---

## ARCHITECTURAL DECISION RECORDS (ADR)

### ADR Creation Criteria
**Three-Part Test (ALL must be true):**
1. **Impact:** Long-term consequences? Affects framework, data model, API, security, or platform?
2. **Alternatives:** Multiple viable options were considered?
3. **Scope:** Cross-cutting and influences system design?

**If ALL true â†’ Suggest ADR:**
```
ðŸ“‹ Architectural decision detected: [brief-description]
   Document reasoning and tradeoffs? Run `/sp.adr [decision-title]`
```

### ADR Examples for This Project
**Expected ADRs:**
1. "Use Docusaurus v3 over Next.js for static site generation"
2. "Use Qdrant Cloud instead of self-hosted vector database"
3. "Use OpenAI Agents SDK instead of LangChain for RAG"
4. "Use Better Auth instead of NextAuth for authentication"
5. "Deploy frontend to GitHub Pages instead of Vercel"

### ADR Workflow
1. Agent detects significant decision during planning/implementation
2. Agent suggests ADR creation (waits for user consent)
3. User approves: `/sp.adr <title>`
4. Agent creates ADR in `history/adr/NNNN-<slug>.md`
5. ADR includes: Context, Decision, Alternatives Considered, Consequences, Status

---

## HUMAN AS TOOL STRATEGY

### Invocation Triggers
**Agent MUST ask user when:**
1. **Ambiguous Requirements:** User intent unclear â†’ Ask 2-3 targeted clarifying questions
2. **Unforeseen Dependencies:** Discovered dependencies not in spec â†’ Surface and ask for prioritization
3. **Architectural Uncertainty:** Multiple valid approaches with significant tradeoffs â†’ Present options
4. **Completion Checkpoint:** Major milestone reached â†’ Summarize work, confirm next steps

### Question Guidelines
**Best Practices:**
- Ask 2-3 focused questions (not 10+)
- Provide context for why you're asking
- Offer 2-3 options with tradeoffs (when applicable)
- State your recommendation (if you have one)

**Example:**
```
I'm implementing the RAG chatbot and need to decide on chunk size:

Options:
1. 512 tokens - Faster search, less context per chunk
2. 1024 tokens - Slower search, more context per chunk
3. Adaptive chunking - Complex, but optimal for varied content

Recommendation: Start with 512 tokens (option 1) for speed, then optimize based on relevance metrics.

What's your preference?
```

---

## EXECUTION CONTRACT (Per Request)

**For Every Request, Agent Must:**

1. **Confirm Surface & Success Criteria** (1 sentence)
   - Example: "Surface: ContentWriter agent. Success: Chapter 3 authored with runnable code examples."

2. **List Constraints, Invariants, Non-Goals**
   - Constraints: Free tier limits, TypeScript strict mode
   - Invariants: No secrets in code, 80% test coverage
   - Non-Goals: Not building CMS, not supporting other languages yet

3. **Produce Artifact with Acceptance Checks**
   - Create the deliverable (code, doc, spec)
   - Include inline checkboxes or test assertions

4. **Add Follow-Ups and Risks** (max 3 bullets)
   - Follow-up: "Integrate chatbot UI with backend API"
   - Risk: "OpenAI rate limit if > 100 queries/day"

5. **Create PHR**
   - Route to appropriate subdirectory (constitution, feature, or general)
   - Fill all template fields (no placeholders)

6. **Suggest ADR (if applicable)**
   - Test decision against three-part test
   - Suggest ADR creation, wait for user consent

---

## MINIMUM ACCEPTANCE CRITERIA (Per Deliverable)

**Every Deliverable Must Have:**
- Clear, testable acceptance criteria
- Explicit error paths and constraints stated
- Smallest viable change (no unrelated edits)
- Code references to modified/inspected files (format: `path:line_start-line_end`)

**Example:**
```
Deliverable: RAG query endpoint

Acceptance Criteria:
- [ ] POST /api/v1/query accepts JSON body: {"query": "string"}
- [ ] Returns JSON: {"answer": "string", "sources": ["string"], "confidence": float}
- [ ] Response time p95 < 3s (load tested)
- [ ] Handles empty query (400 error)
- [ ] Handles OpenAI timeout (503 error with retry message)

Code References:
- `backend/api/routes.py:42-78` - Query endpoint implementation
- `backend/services/rag.py:15-60` - RAG pipeline logic

Constraints:
- Must use OpenAI Agents SDK (not custom LangChain)
- Must log query + response with correlation ID

Non-Goals:
- Not implementing streaming responses (future enhancement)
- Not supporting multi-turn conversations yet
```

---

## FINAL PRINCIPLES SUMMARY

### Measurability Over Aspiration
- âœ… "TypeScript strict mode, 80% test coverage"
- âŒ "High quality code"

### Reversibility Where Possible
- Use feature flags for major UI changes
- Keep old API versions during migration (6-month deprecation)
- Document rollback procedures in runbooks

### Smallest Viable Change
- Don't over-engineer Phase 1
- Build incrementally with quality gates between phases
- Avoid premature abstractions (YAGNI principle)

### Human as Tool
- List explicit cases for user escalation (ambiguity, architecture, blockers)
- Define when agents should pause and ask
- Provide context and options, not just "What should I do?"

### Constitution Compliance
- All agents must check constitution before starting work
- All specification changes require constitution compliance check
- Orchestrator audits compliance at phase gates

---

## REFERENCES

**Documentation Locations:**
- Constitution: `.specify/memory/constitution.md`
- Feature Specs: `specs/<feature>/spec.md`
- Architecture Plans: `specs/<feature>/plan.md`
- Task Lists: `specs/<feature>/tasks.md`
- Prompt History: `history/prompts/` (constitution, feature-name, or general)
- ADRs: `history/adr/`
- Templates: `.specify/templates/`

**Key Contacts:**
- Orchestrator Agent: Primary coordination
- User: Human as Tool for clarifications

**Last Updated:** 2025-12-10
**Version:** 1.0.0
**Status:** Active
